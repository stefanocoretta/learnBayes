---
title: "Introduction to Bayesian Linear Models"
subtitle: "03 - Priors"
author: "Stefano Coretta"
institute: "University of Edinburgh"
editor: source
format:
  mono-light-revealjs:
    theme: [default, custom.scss]
    history: false
filters:
  - tachyonsextra
execute: 
  echo: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
theme_set(theme_minimal())

library(ggeffects)
library(brms)
library(tidybayes)
library(bayesplot)
library(googlesheets4)
gs4_deauth()
library(HDInterval)
library(truncdist)
my_seed <- 0745
```

```{r}
#| label: mald
#| echo: false

mald <- readRDS("./data/mald.rds")
```

## Bayesian belief update

![](/img/prior-update.png){fig-align="center"}

## 

```{r}
#| label: seeing-priors
#| echo: false

library(htmltools)

HTML('<section id="Priors" data-background-iframe="https://seeing-theory.brown.edu/bayesian-inference/index.html#section3" data-background-interactive>
</section>')
```

## Let's start small

$$\text{RT}_i \sim Gaussian(\mu, \sigma)$$

. . .

::: box-note
-   $\text{RT}_i$: Reaction Times

-   $\sim$: distributed according to a

-   $Gaussian()$: Gaussian distribution

-   with mean $\mu$ and standard deviation $\sigma$
:::

. . .

::: box-warning
We **assume** RTs are distributed according to a Gaussian distribution (the assumption can be wrong)

...and in fact it is (RTs are not Gaussian, but we will get to that later).
:::

## 

```{r}
#| label: seeing-gaussian
#| echo: false

library(htmltools)

HTML('<section id="Priors" data-background-iframe="https://seeing-theory.brown.edu/probability-distributions/index.html#section2" data-background-interactive>
</section>')
```

## The empirical rule

```{r}
#| label: empirical-rule-1
#| echo: false

x <- seq(-4, 4, by = 0.01)
y = dnorm(x, 0, 1)

ger_1 <- ggplot() +
  aes(x, y) +
  geom_line(linewidth = 2, colour = "#FFA70B") +
  scale_x_continuous(breaks = c(-4:4), labels = c("", expression(paste(-3, sigma)), expression(paste(-2, sigma)), expression(paste(-1, sigma)), expression(paste(mu)), expression(paste(+1, sigma)), expression(paste(+2, sigma)), expression(paste(+3, sigma)), "")) +
  ylim(0, 0.6) +
  labs(
    x = element_blank(), y = element_blank()
  )
ger_1
```

## The empirical rule

```{r empirical-rule-2, echo=FALSE}
ger_1 +
  geom_ribbon(aes(x = ifelse(x >= -1 & x <= 1, x, NA), ymin = 0, ymax = y), alpha = 0.7, fill = "#8970FF") +
  annotate(
    "segment",
    x = -1, xend = 1, y = 0.45, yend = 0.45,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    linewidth = 1
  ) +
  annotate("label", x = 0, y = 0.45, label = "68%") +
  geom_line(linewidth = 2, colour = "#FFA70B")
```

## The empirical rule

```{r empirical-rule-3, echo=FALSE}
ger_1 +
  geom_ribbon(aes(x = ifelse(x >= -2 & x <= 2, x, NA), ymin = 0, ymax = y), alpha = 0.4, fill = "#8970FF") +
annotate(
    "segment",
    x = -2, xend = 2, y = 0.5, yend = 0.5,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    linewidth = 1
  ) +
  annotate("label", x = 0, y = 0.50, label = "95%") +
  geom_line(linewidth = 2, colour = "#FFA70B")
```

## The empirical rule

```{r empirical-rule-4, echo=FALSE}
ger_1 +
  geom_ribbon(aes(x = x, ymin = 0, ymax = y), alpha = 0.3, fill = "#8970FF") +
  annotate(
    "segment",
    x = -3, xend = 3, y = 0.55, yend = 0.55,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    linewidth = 1
  ) +
  annotate("label", x = 0, y = 0.55, label = "99.7 ≈ 100%") +
  geom_line(linewidth = 2, colour = "#FFA70B")
```

## The empirical rule

```{r empirical-rule-5, echo=FALSE}
x <- seq(-4, 4, by = 0.01)
y = dnorm(x, 0, 1)
ggplot() +
  aes(x, y) +
  geom_ribbon(aes(x = x, ymin = 0, ymax = y), alpha = 0.3, fill = "#8970FF") +
  geom_ribbon(aes(x = ifelse(x >= -2 & x <= 2, x, NA), ymin = 0, ymax = y), alpha = 0.4, fill = "#8970FF") +
  geom_ribbon(aes(x = ifelse(x >= -1 & x <= 1, x, NA), ymin = 0, ymax = y), alpha = 0.7, fill = "#8970FF") +
  geom_line(linewidth = 2, colour = "#FFA70B") +
  annotate(
    "segment",
    x = -1, xend = 1, y = 0.45, yend = 0.45,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    linewidth = 1
  ) +
  annotate("label", x = 0, y = 0.45, label = "68%") +
  annotate(
    "segment",
    x = -2, xend = 2, y = 0.5, yend = 0.5,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    linewidth = 1
  ) +
  annotate("label", x = 0, y = 0.50, label = "95%") +
  annotate(
    "segment",
    x = -3, xend = 3, y = 0.55, yend = 0.55,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    linewidth = 1
  ) +
  annotate("label", x = 0, y = 0.55, label = "99.7 ≈ 100%") +
  scale_x_continuous(breaks = c(-4:4), labels = c("", expression(paste(-3, sigma)), expression(paste(-2, sigma)), expression(paste(-1, sigma)), expression(paste(mu)), expression(paste(+1, sigma)), expression(paste(+2, sigma)), expression(paste(+3, sigma)), "")) +
  ylim(0, 0.6) +
  labs(
    x = element_blank(), y = element_blank()
  )
```

## Distribution of RTs

$$\text{RT}_i \sim Gaussian(\mu, \sigma)$$

<br> <br> <br>

Pick a $\mu$ and $\sigma$.

Report them here: <https://forms.gle/M7juHsxyv5Vbs7Gx7>.

## Let's see what we got!

```{r}
#| label: rt-sheet
#| echo: false
#| message: false
#| warning: false

rt <- read_sheet("https://docs.google.com/spreadsheets/d/1TOJmee8wSKMMHoN9B_0oC3x33gIpvUovlQNqMV0S9vE/edit?usp=sharing", 1)
colnames(rt) <- c("Timestamp", "mean_rt", "sd_rt")

if (nrow(rt) == 0) {
  rt <- tibble(Timestamp = c("a", "b"), mean_rt = c(1000, 2000), sd_rt = c(300, 450))
}

x <- seq(min(rt$mean_rt) - 3 * max(rt$sd_rt), max(rt$mean_rt) + 3 * max(rt$sd_rt))

rt %>%
  filter(mean_rt > 100, sd_rt > 50) %>%
  mutate(
    y = map2(mean_rt, sd_rt, ~dnorm(x, .x, .y)),
    x = list(x)
  ) %>%
  unnest(cols = c(y, x)) %>%
  ggplot(aes(x, y, group = as.character(paste(Timestamp, mean_rt, sd_rt)))) +
  geom_line(size = 1, alpha = 0.5) +
  theme(legend.position = "none") +
  labs(
    x = "RT (ms)", y = "Density",
    title = "Proposed distributions of RTs"
  ) +
  scale_color_brewer(palette = "Paired") +
  xlim(-500, 2500)
```

## Distribution of RTs

$$\text{RT}_i \sim Gaussian(\mu, \sigma)$$

$$\mu = ...?$$

$$\sigma = ...?$$

. . .

::: box-tip
When uncertain, use probabilities!
:::

## Priors of the parameters

$$
\begin{align}
\text{RT}_i & \sim Gaussian(\mu, \sigma)\\
\mu & \sim Gaussian(\mu_1, \sigma_1)\\
\sigma & \sim Cauchy(0, \sigma_2)\\
\end{align}
$$

. . .

::: box-note
Let's pick $\mu_1$ and $\sigma_1$.

We can use the empirical rule.
:::

## Prior for $\mu$

::: box-note
-   Let's say that the mean is between 500 and 2500 ms at 95% confidence.

-   Get $\mu_1$

    -   `mean(c(500, 2500))` = 1500

-   Get $\sigma_2$

    -   `(2500 - 1500) / 2` = 500
:::

. . .

$$
\begin{align}
\text{RT}_i & \sim Gaussian(\mu, \sigma)\\
\mu & \sim Gaussian(\mu_1 = 1500, \sigma_1 = 500)\\
\sigma & \sim Cauchy(0, \sigma_2)\\
\end{align}
$$

## Prior for $\mu$: plot

```{r}
#| label: mu-prior-plot

ggplot(tibble(x = c(-100, 3100)), aes(x = x)) +
  stat_function(fun = dnorm, geom = "area", fill = "lightblue",
                args = list(1500, 500))
```

## Prior for $\sigma$

```{r hdi-cauchy}
# library(HDInterval)

round(inverseCDF(c(0.025, 0.5, 0.975), ptrunc, spec = "cauchy", a = 0, scale = 10))

round(inverseCDF(c(0.025, 0.5, 0.975), ptrunc, spec = "cauchy", a = 0, scale = 25))

round(inverseCDF(c(0.025, 0.5, 0.975), ptrunc, spec = "cauchy", a = 0, scale = 50))
```

## Prior for $\sigma$: plot

```{r}
#| label: sigma-prior-plot

ggplot(tibble(x = c(0, 500)), aes(x = x)) +
  stat_function(fun = dcauchy, geom = "area", fill = "tomato4",
                args = list(0, 25))
```

## Prior predictive checks: sample prior

```{r}
#| label: brm-3-priorpp

brm_3_priorpp <- brm(
  RT ~ 1,
  family = gaussian,
  prior = c(
    prior(normal(1500, 500), class = Intercept),
    prior(cauchy(0, 25), class = sigma)
  ),
  data = mald,
  sample_prior = "only",
  cores = 4,
  file = "data/cache/brm_3_priorpp",
  seed = my_seed
)
```

## Prior predictive checks: sample prior

```{r}
#| label: brm-3-priorpp-summ

summary(brm_3_priorpp)
```


## Prior predictive checks: plot

```{r}
#| label: brm-3-priorpp-plot

set.seed(my_seed)
brm_3_pppreds <- posterior_predict(brm_3_priorpp, newdata = tibble(y = 1), ndraws = 1e3) |>
  as.vector()

ggplot() +
  aes(x = brm_3_pppreds) +
  geom_density(fill = "forestgreen") +
  geom_rug()
```

## Prior predictive checks: plot (zoom in)

```{r}
#| label: brm-3-priorpp-plot-2
#| warning: false

ggplot() +
  aes(x = brm_3_pppreds) +
  geom_density(fill = "forestgreen") +
  xlim(-1000, 3500) +
  geom_rug()
```

## Run the model

```{r}
#| label: brm-3

brm_3 <- brm(
  RT ~ 1,
  family = gaussian,
  prior = c(
    prior(normal(1500, 500), class = Intercept),
    prior(cauchy(0, 25), class = sigma)
  ),
  data = mald,
  cores = 4,
  file = "data/cache/brm_3",
  seed = my_seed
)
```

## Model summary

```{r}
#| label: brm-3-summ

summary(brm_3)
```

## Posterior predictive checks

```{r}
#| label: brm-3-pp

pp_check(brm_3, ndraws = 100)
```

## Summary

::: box-note

- Priors are probability distributions that convey prior knowledge about the model parameters.

- Gaussian family
  - $\mu$: Gaussian prior.
  - $\sigma$: (Truncated) Cauchy prior (but also Student-t and others).

- Use the empirical rule to work out Gaussian priors and the `HDIinterval::inverseCDF()` function for other families.

- Prior predictive checks are fundamental and should be run during the study design, **before** data collection (or in any case without being informed by the data).
:::
